---
title: 机器学习算法清单
toc: true
date: 2018-09-04 10:55:37
tags: 机器学习
categories: 机器学习
---

一般来说，机器学习算法分为三种类型：

1. **监督学习**

   **工作原理**：该算法由一个目标/结果变量（或因变量）组成，该变量（或因变量）由给定的一组预测器（自变量）进行预测得到。使用这些变量集，我们可以生成输入映射到期望输出的函数。通过训练算法模型，让模型在训练数据上得到期望的准确度。

   **监督学习的例子**包括：回归、决策树、随机森林、KNN、Logistic 回归等。

2. **非监督学习**

   **工作原理**：该算法没有任何目标/结果变量（或因变量）来预测或估计。它用于对样本中的不同类别进行聚类，广泛用于在不知道标签的情况下对不同群体进行划分。

   **无监督学习的例子**包括：Apriori 算法，k-均值。

3. **增强学习**

   **工作原理**：机器被训练来做出特定的决定。它是这样工作的：机器通过反复试验不断训练自己，从过去的经验中学习，并试图运用最好的知识，作出准确的决策。

   **强化学习的例子**包括：马尔可夫（Markov）决策过程。



# 常见的机器学习算法列表

1. 线性回归
2. 逻辑回归
3. 决策树
4. SVM
5. 朴素贝叶斯
6. k近邻
7. k-聚类
8. 随机森林
9. 降维算法
10. 梯度提升算法
    1. GBM
    2. XGBoost
    3. LightGBM
    4. CatBoost

## 线性回归

**线性回归（Linear Regression）**基于连续变量$s$的实数值估计（房屋价格，通话数量，总销售额等）。在这里，我们通过拟合一条最佳直线来建立自变量$x$和因变量$y$之间的关系。这个最佳拟合线称为回归线，用线性方程$y= w*x+b$表示。

系数 $w$ 和 $b$ 是基于最小化数据点与回归线之间的距离之差的平方和而推导得到的。 

线性回归主要有两类：简单线性回归和多元线性回归。**简单线性回归**的特点是只有一个自变量。**多元线性回归**的特征是有多个（大于 1）独立变量。当然，为了找到最佳拟合线，可以使用多项式拟合或曲线拟合，分别称为**多项式回归**和**曲线回归**。

Python代码：

```python
from sklearn.datasets import load_boston
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# 波士顿房价回归数据
data = load_boston()
X = data.get('data')
y = data.get('target')

# 分割训练集与测试集
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2,
                                                    random_state=123)

# 线性回归
linear = LinearRegression(normalize=True)

linear.fit(X_train, y_train)
linear.score(X_train, y_train)

# Equation coefficient and Intercept
print('Coefficient: \n', linear.coef_)
print('Intercept: \n', linear.intercept_)

# Predict Output
predicted = linear.predict(X_test)
print(predicted)
```

## 逻辑回归

**逻辑回归（Logistic Regression）**是一种分类算法而不是回归算法。它根据给定的一组自变量估计离散值（二进制值如 0/1、是/否、真/假）。简单地说，它通过将数据拟合到 logit 函数来预测事件发生的概率。因此称之为 logit 回归。因为它预测的是概率值，所以输出介于 0 到 1 之间。

它的目标是最大化观测样本值的似然性，而不是像线性回归那样最小化误差的平方和。

为什么使用log函数？

log函数是代替阶跃函数的最好选择之一。

```python
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 虹膜分类数据
data = load_iris()
X = data.get('data')
y = data.get('target')

# 分割训练集与测试集
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2,
                                                    random_state=123)

# 线性回归
lr = LogisticRegression()

lr.fit(X_train, y_train)
print(lr.score(X_train, y_train))

# Equation coefficient and Intercept
print('Coefficient: \n', lr.coef_)
print('Intercept: \n', lr.intercept_)

# Predict Output
predicted = lr.predict(X_test)
print(predicted == y_test)
```

